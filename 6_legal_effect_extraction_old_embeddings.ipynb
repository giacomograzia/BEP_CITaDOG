{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legal Effect Extraction\n",
    "\n",
    "Giacomo Grazia\n",
    "\n",
    "Academic Year 2024-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data for API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LLM-based classification (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Api function with prompt 1 (categorization based on decision headline and description only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess each row and call the OpenAI API for categorization\n",
    "def categorize_with_openai(row):\n",
    "    \"\"\"\n",
    "    Processes a row to extract headline and description, prepares a categorization prompt,\n",
    "    and calls the OpenAI API to determine the appropriate category/categories.\n",
    "\n",
    "    :param row: A row from the DataFrame containing 'headline' and 'description'.\n",
    "    :return: list of categories assigned by the API, if any.\n",
    "    \"\"\"\n",
    "    decision_headline = row.get(\"headline\", \"\")\n",
    "    decision_description = row.get(\"description\", \"\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Given the following headline and description of an administrative decision, \n",
    "    categorize it into one of the following 6 categories:\n",
    "    \n",
    "    - \"verguning verlening\": Decisions to grant a license\n",
    "    - \"wijziging of aanpassen\": Decisions to amend/modify a license\n",
    "    - \"overdracht\": Decisions to transfer a license to another party (including name changes)\n",
    "    - \"intrekking of beëindiging\": Decisions to revoke/withdraw a license\n",
    "    - \"schorsing\": Decisions to suspend a license\n",
    "    - \"vernieuwing of verlenging\": Decisions to renew or extend a license\n",
    "\n",
    "    Guidelines for Categorization:\n",
    "    1. You may assign ONLY ONE category, if applicable. \n",
    "    2. If no category is relevant, return nothing.\n",
    "\n",
    "    Input:\n",
    "    - Headline: {decision_headline}\n",
    "    - Description: {decision_description}\n",
    "\n",
    "    Output Format:\n",
    "    - If a category is identified, return a list in this format:\n",
    "        [\"assigned_category\"]\n",
    "    - If no category is identified, return an empty list like this:\n",
    "        []\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the OpenAI API\n",
    "    try:\n",
    "        response = OpenAI().chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant for categorizing legal decisions into 6 categories.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            # max_tokens=150,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        \n",
    "        # Extract the assistant's response\n",
    "        assistant_output = response.choices[0].message.content.strip()\n",
    "        print(assistant_output)\n",
    "        return json.loads(assistant_output)  # Parse JSON response from API\n",
    "\n",
    "    except Exception as e:\n",
    "        return [f\"Error: {str(e)}\"]  # Return error message in a list format\n",
    "\n",
    "df_merged[\"category_single_gpt_4o-mini\"] = df_merged.progress_apply(categorize_with_openai, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LLM-based classification (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Api function with prompt 2 (categorization based on headline, description and full text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess each row and call the OpenAI API for categorization\n",
    "def categorize_with_openai(row):\n",
    "    \"\"\"\n",
    "    Processes a row to extract headline and description, prepares a categorization prompt,\n",
    "    and calls the OpenAI API to determine the appropriate category/categories.\n",
    "\n",
    "    :param row: A row from the DataFrame containing 'headline' and 'description'.\n",
    "    :return: list of categories assigned by the API, if any.\n",
    "    \"\"\"\n",
    "    decision_headline = row.get(\"headline\", \"\")\n",
    "    decision_description = row.get(\"description\", \"\")\n",
    "    decision_text = row.get(\"text_pypdf2\", \"\")\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the following headline, description and text of an administrative decision, \n",
    "    categorize the decision into one of the following 6 categories:\n",
    "    \n",
    "    - \"verguning verlening\": Decisions to grant a license\n",
    "    - \"wijziging of aanpassen\": Decisions to amend/modify a license\n",
    "    - \"overdracht\": Decisions to transfer a license to another party (including name changes)\n",
    "    - \"intrekking of beëindiging\": Decisions to revoke/withdraw a license\n",
    "    - \"schorsing\": Decisions to suspend a license\n",
    "    - \"vernieuwing of verlenging\": Decisions to renew or extend a license\n",
    "\n",
    "    Guidelines for Categorization:\n",
    "    1. You may assign ONLY ONE category, if applicable. \n",
    "    2. If no category is relevant, return nothing.\n",
    "\n",
    "    Input:\n",
    "    - Headline: {decision_headline}\n",
    "    - Description: {decision_description}\n",
    "    - Text: {decision_text}\n",
    "\n",
    "    Output Format:\n",
    "    - If a category is identified, return a list containing the category as a string, like this:\n",
    "        [\"assigned_category\"]\n",
    "    - If no category is identified, return an empty list like this:\n",
    "        []\n",
    "    \"\"\"\n",
    "    \n",
    "    # print(prompt)\n",
    "\n",
    "    # Call the OpenAI API\n",
    "    try:\n",
    "        response = OpenAI().chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant for categorizing legal decisions into 6 categories.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            # max_tokens=150,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        \n",
    "        # Extract the assistant's response\n",
    "        assistant_output = response.choices[0].message.content.strip()\n",
    "        # print(assistant_output)\n",
    "        return json.loads(assistant_output)  # Parse JSON response from API\n",
    "\n",
    "    except Exception as e:\n",
    "        return [f\"Error: {str(e)}\"]  # Return error message in a list format\n",
    "\n",
    "df_merged[\"category_single_from_TEXT_gpt_4o-mini\"] = df_merged.progress_apply(categorize_with_openai, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Comparison of approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Creating word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1 Create spaCy Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings spacy on combined text\n",
    "import spacy\n",
    "\n",
    "# Load the Dutch spaCy model\n",
    "nlp = spacy.load(\"nl_core_news_lg\")\n",
    "\n",
    "# Combine headline and description\n",
    "df_merged[\"combined_text\"] = df_merged[\"headline\"] + \" \" + df_merged[\"description\"]\n",
    "\n",
    "# Create embeddings using spaCy\n",
    "def get_embeddings(text):\n",
    "    doc = nlp(text)\n",
    "    return doc.vector  # Returns the document vector (dense representation)\n",
    "\n",
    "# Embeddings of combined text\n",
    "df_merged[\"embedding_spacy_nl_lg_combined_text\"] = df_merged[\"combined_text\"].apply(get_embeddings) #ok\n",
    "\n",
    "# Embeddings of decision body\n",
    "df_merged[\"embedding_spacy_nl_lg_body\"] = df_merged[\"text_pypdf2\"].progress_apply(get_embeddings) #ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2 Create OpenAI Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "OpenAI.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Getting embeddings for the combined text (headline - description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# Function to get embeddings using OpenAI API\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Generates an embedding for the given text using the specified OpenAI model.\n",
    "\n",
    "    :param text: The text to embed.\n",
    "    :param model: The embedding model to use (default: \"text-embedding-3-small\").\n",
    "    :return: A list representing the embedding vector.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(input=text, model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Apply the embedding function to all rows\n",
    "tqdm.pandas()  # Initialize tqdm for pandas\n",
    "df_merged['embedding_combined_text-embedding-3-small'] = df_merged['combined_text'].progress_apply(\n",
    "    lambda x: get_embedding(x, model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Getting embeddings for the decisions' full text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings have a token limit of 8192 tokens. \n",
    "# We will truncate the text to fit within this limit.\n",
    "\n",
    "def truncate_text(text, row_index, max_tokens=8192, encoding_name=\"cl100k_base\"):\n",
    "    \"\"\"\n",
    "    Truncates text to fit within the token limit and logs rows exceeding the limit.\n",
    "\n",
    "    :param text: str, the input text to truncate.\n",
    "    :param row_index: int, the index of the row (for logging purposes).\n",
    "    :param max_tokens: int, the maximum number of tokens allowed.\n",
    "    :param encoding_name: str, the encoding model name.\n",
    "    :return: str, truncated text that fits within the token limit.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    \n",
    "    if len(tokens) > max_tokens:\n",
    "        print(f\"Row {row_index} exceeded the {max_tokens} token limit. Original tokens: {len(tokens)}\")\n",
    "        tokens = tokens[:max_tokens]\n",
    "    \n",
    "    return encoding.decode(tokens)\n",
    "\n",
    "\n",
    "# Truncate text in the DataFrame before embedding\n",
    "df['truncated_text'] = df.apply(\n",
    "    lambda row: truncate_text(row['text_pypdf2'], row.name, max_tokens=8191, encoding_name=\"cl100k_base\"),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding body openai\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to get embeddings using OpenAI API\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Generates an embedding for the given text using the specified OpenAI model.\n",
    "\n",
    "    :param text: The text to embed.\n",
    "    :param model: The embedding model to use (default: \"text-embedding-3-small\").\n",
    "    :return: A list representing the embedding vector.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(input=text, model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Apply embeddings to the truncated text\n",
    "tqdm.pandas()  # Initialize tqdm for pandas\n",
    "df['embedding_decision-body_text-embedding-3-small'] =  df['truncated_text'].progress_apply(\n",
    "    lambda x: get_embedding(x, model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "# Save the DataFrame to a file\n",
    "df.to_csv('df_merged_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Visualizing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 Visualizing spaCy embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_merged = pd.read_csv('../df_merged_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'file_number', 'text_pypdf2', 'headline', 'description',\n",
       "       'publication_date', 'decision_date', 'case', 'parties', 'file_link',\n",
       "       'parties_list', 'extracted_parties_gpt', 'extracted_parties_gpt_v2',\n",
       "       'extracted_parties_gpt_v3', 'categories_rule_based',\n",
       "       'categories_gpt_4o-mini', 'jaccard_similarity', 'combined_text',\n",
       "       'embedding_headline-description', 'truncated_text',\n",
       "       'embedding_decision-body_text-embedding-3-small',\n",
       "       'category_single_gpt_4o-mini', 'category_single_from_TEXT_gpt_4o-mini'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'embedding_spacy_nl_lg_combined_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TUEindhoven/BDS/Y3S1_BEP/BEP_CITaDOG/.conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding_spacy_nl_lg_combined_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert embeddings to a matrix for clustering\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m embedding_matrix_combined_text \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(\u001b[43mdf_merged\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding_spacy_nl_lg_combined_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      4\u001b[0m embedding_matrix_body \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(df_merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_spacy_nl_lg_body\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TUEindhoven/BDS/Y3S1_BEP/BEP_CITaDOG/.conda/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TUEindhoven/BDS/Y3S1_BEP/BEP_CITaDOG/.conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding_spacy_nl_lg_combined_text'"
     ]
    }
   ],
   "source": [
    "# Convert embeddings to a matrix for clustering\n",
    "import numpy as np\n",
    "embedding_matrix_combined_text = np.vstack(df_merged[\"embedding_spacy_nl_lg_combined_text\"].values)\n",
    "embedding_matrix_body = np.vstack(df_merged[\"embedding_spacy_nl_lg_body\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering COMBINED TEXT\n",
    "n_clusters = 5 # since 5 categories have been assigned\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df_merged[\"cluster_kmeans_combined_text\"] = kmeans.fit_predict(embedding_matrix_combined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) k-means on spaCy embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
